{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3d4ee2-c0c8-4f88-8fe3-a07676bddeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dda4ddc-68fb-4da7-bf7b-d849d8d1c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data.h5 with 8017 training and 326 test images.\n"
     ]
    }
   ],
   "source": [
    "# function to load images\n",
    "def load_images(folder, label, size):\n",
    "    images, labels = [], []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            path = os.path.join(folder, file)\n",
    "            try:\n",
    "                img = Image.open(path).resize((size, size)).convert('RGB')\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped {file}: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# Function to create hdf5 files from folder\n",
    "def create_hdf5_from_folders(root_folder, output_file='data.h5', image_size=64):\n",
    "    X_train, Y_train, X_test, Y_test = [], [], [], []\n",
    "\n",
    "    # Training set\n",
    "    train_humans_path = os.path.join(root_folder, \"training_set/training_set/humans\")\n",
    "    train_nonhumans_path = os.path.join(root_folder, \"training_set/training_set/non-humans\")\n",
    "\n",
    "    x, y = load_images(train_humans_path, 1, image_size)\n",
    "    X_train.extend(x)\n",
    "    Y_train.extend(y)\n",
    "\n",
    "    x, y = load_images(train_nonhumans_path, 0, image_size)\n",
    "    X_train.extend(x)\n",
    "    Y_train.extend(y)\n",
    "\n",
    "    # Test set\n",
    "    test_humans_path = os.path.join(root_folder, \"test_set/test_set/humans\")\n",
    "    test_nonhumans_path = os.path.join(root_folder, \"test_set/test_set/non-humans\")\n",
    "\n",
    "    x, y = load_images(test_humans_path, 1, image_size)\n",
    "    X_test.extend(x)\n",
    "    Y_test.extend(y)\n",
    "\n",
    "    x, y = load_images(test_nonhumans_path, 0, image_size)\n",
    "    X_test.extend(x)\n",
    "    Y_test.extend(y)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    # Save to HDF5\n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        f.create_dataset('train_set_x', data=X_train)\n",
    "        f.create_dataset('train_set_y', data=Y_train)\n",
    "        f.create_dataset('test_set_x', data=X_test)\n",
    "        f.create_dataset('test_set_y', data=Y_test)\n",
    "\n",
    "    print(f\"Saved to {output_file} with {X_train.shape[0]} training and {X_test.shape[0]} test images.\")\n",
    "\n",
    "# Example usage\n",
    "create_hdf5_from_folders(\"human-and-non-human\", output_file='data.h5', image_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40fd9b5c-8ec2-4fd0-ad17-523570251c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataset = h5py.File(\"data.h5\", \"r\")\n",
    "    X_train = np.array(dataset[\"train_set_x\"][:])\n",
    "    Y_train = np.array(dataset[\"train_set_y\"][:])\n",
    "    X_test = np.array(dataset[\"test_set_x\"][:])\n",
    "    Y_test = np.array(dataset[\"test_set_y\"][:])\n",
    "\n",
    "    Y_train = Y_train.reshape((1, Y_train.shape[0]))\n",
    "    Y_test = Y_test.reshape((1, Y_test.shape[0]))\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d01e90-9690-4f97-ac61-dc66e307951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.  # Normalize\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).T\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49835a8b-1a54-48be-88c3-a1c916e1d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = (Z1, A1, Z2, A2)\n",
    "    return A2, cache\n",
    "\n",
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2)) / m\n",
    "    return np.squeeze(cost)\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    Z1, A1, Z2, A2 = cache\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate=0.01):\n",
    "    parameters['W1'] -= learning_rate * grads['dW1']\n",
    "    parameters['b1'] -= learning_rate * grads['db1']\n",
    "    parameters['W2'] -= learning_rate * grads['dW2']\n",
    "    parameters['b2'] -= learning_rate * grads['db2']\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2919f3-b614-4935-be5b-05d0e40e4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, n_h, num_iterations=1000, learning_rate=0.01, print_cost=False):\n",
    "    np.random.seed(3)\n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(f\"Cost after iteration {i}: {cost:.4f}\")\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3de859-fddf-4e37-8e2f-e294ca9cd625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931\n",
      "Cost after iteration 100: 0.6715\n",
      "Cost after iteration 200: 0.5976\n",
      "Cost after iteration 300: 0.5123\n",
      "Cost after iteration 400: 0.4332\n",
      "Cost after iteration 500: 0.3657\n",
      "Cost after iteration 600: 0.3134\n",
      "Cost after iteration 700: 0.2734\n",
      "Cost after iteration 800: 0.2425\n",
      "Cost after iteration 900: 0.2180\n",
      "Cost after iteration 1000: 0.1984\n",
      "Cost after iteration 1100: 0.1824\n",
      "Cost after iteration 1200: 0.1691\n",
      "Cost after iteration 1300: 0.1580\n",
      "Cost after iteration 1400: 0.1485\n",
      "Cost after iteration 1500: 0.1404\n",
      "Cost after iteration 1600: 0.1334\n",
      "Cost after iteration 1700: 0.1273\n",
      "Cost after iteration 1800: 0.1220\n",
      "Cost after iteration 1900: 0.1172\n",
      "Train Accuracy: 96.85667955594361 %\n",
      "Test Accuracy: 91.41104294478528 %\n"
     ]
    }
   ],
   "source": [
    "def predict(parameters, X):\n",
    "    A2, _ = forward_propagation(X, parameters)\n",
    "    return (A2 > 0.5).astype(int)\n",
    "\n",
    "parameters = model(X_train, Y_train, n_h=7, num_iterations=2000, learning_rate=0.005, print_cost=True)\n",
    "\n",
    "train_preds = predict(parameters, X_train)\n",
    "test_preds = predict(parameters, X_test)\n",
    "\n",
    "print(\"Train Accuracy:\", 100 - np.mean(np.abs(train_preds - Y_train)) * 100, \"%\")\n",
    "print(\"Test Accuracy:\", 100 - np.mean(np.abs(test_preds - Y_test)) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
